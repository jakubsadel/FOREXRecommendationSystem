{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data=yf.download(tickers='EURUSD=X',start='2011-12-31',end='2019-12-31',interval ='1d')\n",
    "df = df.filter(['Close'])\n",
    "dataset = df.values\n",
    "train_len = math.ceil( len(dataset) *.8) \n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "training_data = scaler.fit_transform(dataset[:train_len , : ]) \n",
    "x_train =[] \n",
    "y_train =[] \n",
    "\n",
    "for i in range(60, len(training_data)):\n",
    "    x_train.append(training_data[i-60:i,0])\n",
    "    y_train.append(training_data[i,0])\n",
    "    \n",
    "x_train,y_train = np.array(x_train), np.array(y_train)\n",
    "x_train= np.reshape(x_train,( x_train.shape[0] ,x_train.shape[1] ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-30</th>\n",
       "      <td>1.295219</td>\n",
       "      <td>1.299596</td>\n",
       "      <td>1.290606</td>\n",
       "      <td>1.295605</td>\n",
       "      <td>1.295605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02</th>\n",
       "      <td>1.296008</td>\n",
       "      <td>1.296395</td>\n",
       "      <td>1.292257</td>\n",
       "      <td>1.296008</td>\n",
       "      <td>1.296008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>1.293628</td>\n",
       "      <td>1.306592</td>\n",
       "      <td>1.293628</td>\n",
       "      <td>1.294096</td>\n",
       "      <td>1.294096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>1.305398</td>\n",
       "      <td>1.307395</td>\n",
       "      <td>1.290206</td>\n",
       "      <td>1.305602</td>\n",
       "      <td>1.305602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>1.293092</td>\n",
       "      <td>1.294297</td>\n",
       "      <td>1.278527</td>\n",
       "      <td>1.293142</td>\n",
       "      <td>1.293142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>1.109299</td>\n",
       "      <td>1.109755</td>\n",
       "      <td>1.107064</td>\n",
       "      <td>1.109385</td>\n",
       "      <td>1.109385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25</th>\n",
       "      <td>1.109139</td>\n",
       "      <td>1.110864</td>\n",
       "      <td>1.107788</td>\n",
       "      <td>1.109016</td>\n",
       "      <td>1.109016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>1.109509</td>\n",
       "      <td>1.110494</td>\n",
       "      <td>1.108279</td>\n",
       "      <td>1.109545</td>\n",
       "      <td>1.109545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>1.110124</td>\n",
       "      <td>1.118068</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>1.110112</td>\n",
       "      <td>1.110112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>1.118155</td>\n",
       "      <td>1.122070</td>\n",
       "      <td>1.118155</td>\n",
       "      <td>1.118230</td>\n",
       "      <td>1.118230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2082 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close  Volume\n",
       "Date                                                                 \n",
       "2011-12-30  1.295219  1.299596  1.290606  1.295605   1.295605       0\n",
       "2012-01-02  1.296008  1.296395  1.292257  1.296008   1.296008       0\n",
       "2012-01-03  1.293628  1.306592  1.293628  1.294096   1.294096       0\n",
       "2012-01-04  1.305398  1.307395  1.290206  1.305602   1.305602       0\n",
       "2012-01-05  1.293092  1.294297  1.278527  1.293142   1.293142       0\n",
       "...              ...       ...       ...       ...        ...     ...\n",
       "2019-12-24  1.109299  1.109755  1.107064  1.109385   1.109385       0\n",
       "2019-12-25  1.109139  1.110864  1.107788  1.109016   1.109016       0\n",
       "2019-12-26  1.109509  1.110494  1.108279  1.109545   1.109545       0\n",
       "2019-12-27  1.110124  1.118068  1.110000  1.110112   1.110112       0\n",
       "2019-12-30  1.118155  1.122070  1.118155  1.118230   1.118230       0\n",
       "\n",
       "[2082 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=yf.download(tickers='EURUSD=X',start='2011-12-31',end='2019-12-31',interval ='1d')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = scaler.transform(dataset[train_len - 60: , : ])\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(60,len(test_data)):\n",
    "    x_test.append(test_data[i-60:i,0])\n",
    "    y_test.append(test_data[i,0])\n",
    "    \n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "forexPredictor = Sequential()\n",
    "forexPredictor.add(LSTM(50, return_sequences = True, input_shape=(x_train.shape[1], 1)))\n",
    "forexPredictor.add(Dropout(0.2))\n",
    "forexPredictor.add(LSTM( 50, return_sequences = False))\n",
    "forexPredictor.add(Dropout(0.2))\n",
    "forexPredictor.add(Dense(50))\n",
    "forexPredictor.add(Dense(1))\n",
    "forexPredictor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "forexPredictor.save('forex_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "51/51 [==============================] - 8s 63ms/step - loss: 0.0681 - val_loss: 4.4937e-04\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0049 - val_loss: 8.2310e-04\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0044 - val_loss: 4.2949e-04\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0041 - val_loss: 4.8080e-04\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0038 - val_loss: 4.2018e-04\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0032 - val_loss: 4.1674e-04\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0032 - val_loss: 8.7179e-04\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0032 - val_loss: 5.7302e-04\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0027 - val_loss: 4.4494e-04\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0023 - val_loss: 3.9573e-04\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0027 - val_loss: 4.1360e-04\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0023 - val_loss: 4.6409e-04\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0021 - val_loss: 4.0904e-04\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0027 - val_loss: 3.9229e-04\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 2s 41ms/step - loss: 0.0023 - val_loss: 6.9493e-04\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 2s 41ms/step - loss: 0.0021 - val_loss: 3.9678e-04\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 2s 38ms/step - loss: 0.0020 - val_loss: 3.6971e-04\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0018 - val_loss: 4.0364e-04\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0018 - val_loss: 4.4923e-04\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0017 - val_loss: 4.6601e-04\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0018 - val_loss: 3.9685e-04\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0015 - val_loss: 3.5725e-04\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0017 - val_loss: 3.6015e-04\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.0017 - val_loss: 3.7180e-04\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0015 - val_loss: 3.5614e-04\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0016 - val_loss: 3.3683e-04\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0016 - val_loss: 4.3130e-04\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0016 - val_loss: 3.3156e-04\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0015 - val_loss: 3.8151e-04\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0014 - val_loss: 3.4539e-04\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0014 - val_loss: 6.8800e-04\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0015 - val_loss: 3.6272e-04\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0014 - val_loss: 5.1503e-04\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0015 - val_loss: 3.0006e-04\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0015 - val_loss: 2.9743e-04\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0014 - val_loss: 8.9695e-04\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 2s 38ms/step - loss: 0.0015 - val_loss: 3.0966e-04\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0013 - val_loss: 3.3103e-04\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 2s 38ms/step - loss: 0.0013 - val_loss: 2.8143e-04\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0013 - val_loss: 2.8643e-04\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0013 - val_loss: 3.5249e-04\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 2s 39ms/step - loss: 0.0013 - val_loss: 5.4601e-04\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0013 - val_loss: 2.8602e-04\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0015 - val_loss: 3.0431e-04\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0011 - val_loss: 2.7910e-04\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.0014 - val_loss: 2.5511e-04\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0013 - val_loss: 3.1293e-04\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0013 - val_loss: 4.0617e-04\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 2s 39ms/step - loss: 0.0013 - val_loss: 3.4303e-04\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0014 - val_loss: 3.3687e-04\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 2s 38ms/step - loss: 0.0012 - val_loss: 5.7999e-04\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 2s 38ms/step - loss: 0.0012 - val_loss: 2.7404e-04\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 2s 39ms/step - loss: 0.0013 - val_loss: 2.7567e-04\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0013 - val_loss: 2.5325e-04\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0012 - val_loss: 2.4016e-04\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0012 - val_loss: 2.2643e-04\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 0.0014 - val_loss: 2.2258e-04\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 2s 38ms/step - loss: 0.0012 - val_loss: 2.2350e-04\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0012 - val_loss: 4.6243e-04\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 2s 38ms/step - loss: 0.0012 - val_loss: 2.7817e-04\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0012 - val_loss: 2.3626e-04\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0012 - val_loss: 2.4516e-04\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0013 - val_loss: 2.4084e-04\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0011 - val_loss: 3.0336e-04\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0013 - val_loss: 2.2410e-04\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0013 - val_loss: 2.1305e-04\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0011 - val_loss: 2.1453e-04\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0012 - val_loss: 2.4391e-04\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0012 - val_loss: 4.8489e-04\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0014 - val_loss: 2.2040e-04\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0011 - val_loss: 3.7389e-04\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 2s 40ms/step - loss: 0.0010 - val_loss: 2.2703e-04\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0011 - val_loss: 1.8945e-04\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0012 - val_loss: 2.5275e-04\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.0012 - val_loss: 1.9787e-04\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 9.8248e-04 - val_loss: 2.3727e-04\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0012 - val_loss: 1.8657e-04\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0011 - val_loss: 1.9466e-04\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0014 - val_loss: 3.1970e-04\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0011 - val_loss: 3.6256e-04\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0011 - val_loss: 1.8074e-04\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0011 - val_loss: 2.0791e-04\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0010 - val_loss: 1.7858e-04\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 9.9869e-04 - val_loss: 3.1939e-04\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0011 - val_loss: 1.7610e-04\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0011 - val_loss: 1.7209e-04\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0011 - val_loss: 3.2309e-04\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.0010 - val_loss: 2.0526e-04\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 0.0013 - val_loss: 1.7913e-04\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0010 - val_loss: 2.0170e-04\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0014 - val_loss: 2.5040e-04\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0013 - val_loss: 1.6932e-04\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0012 - val_loss: 7.1907e-04\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 0.0012 - val_loss: 2.4769e-04\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 0.0010 - val_loss: 1.7470e-04\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0011 - val_loss: 2.4262e-04\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0011 - val_loss: 3.0868e-04\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.0010 - val_loss: 2.6418e-04\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0011 - val_loss: 1.6759e-04\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 0.0011 - val_loss: 1.6459e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x112a6d9a388>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forexPredictor.fit(x_train, y_train, validation_data=(x_test,y_test), epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[[1.22242786]\n",
      " [1.2206639 ]\n",
      " [1.21986435]\n",
      " [1.21934983]\n",
      " [1.21897187]\n",
      " [1.21866658]\n",
      " [1.21839332]\n",
      " [1.21812496]\n",
      " [1.21784472]\n",
      " [1.21754372]]\n"
     ]
    }
   ],
   "source": [
    "end_date = (datetime.today() - timedelta(days=0)).strftime('%Y-%m-%d')\n",
    "start_date = (datetime.today() - timedelta(days=84)).strftime('%Y-%m-%d')\n",
    "user_df = yf.download(tickers='EURUSD=X', start=start_date, end=end_date, interval='1d')\n",
    "user_df = user_df.filter(['Close'])\n",
    "user_data_value = user_df.values\n",
    "user_data = scaler.transform(user_data_value)\n",
    "forex_input = []\n",
    "for i in range(60, len(user_data)):\n",
    "    forex_input.append(user_data[i - 60:i, 0])\n",
    "temp_input = list(forex_input)\n",
    "temp_input = temp_input[0].tolist()\n",
    "forex_input = np.array(forex_input)\n",
    "forex_input = np.reshape(forex_input, (forex_input.shape[0], forex_input.shape[1], 1))\n",
    "\n",
    "\n",
    "\n",
    "lstm_output = []\n",
    "n_steps = 60\n",
    "i = 0\n",
    "\n",
    "while i < 10:\n",
    "\n",
    "        if (len(temp_input) > n_steps):\n",
    "            forex_input = np.array(temp_input[1:])\n",
    "            forex_input = forex_input.reshape(1, -1)\n",
    "            forex_input = forex_input.reshape((1, n_steps, 1))\n",
    "            yhat = forexPredictor.predict(forex_input)\n",
    "            temp_input.extend(yhat[0].tolist())\n",
    "            temp_input = temp_input[1:]\n",
    "            lstm_output.extend(yhat.tolist())\n",
    "            i = i + 1\n",
    "        else:\n",
    "            forex_input = forex_input.reshape((1, n_steps, 1))\n",
    "            yhat = forexPredictor.predict(forex_input)\n",
    "            temp_input.extend(yhat[0].tolist())\n",
    "            lstm_output.extend(yhat.tolist())\n",
    "            i = i + 1\n",
    "\n",
    "predictions = scaler.inverse_transform(lstm_output)\n",
    "\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3535326394388507,\n",
       " 0.3537242281231987,\n",
       " 0.3874536011938434,\n",
       " 0.3791119174222466,\n",
       " 0.4030796955053093,\n",
       " 0.42439721957342735,\n",
       " 0.40584308449027295,\n",
       " 0.4034345891315003,\n",
       " 0.3925611736945034,\n",
       " 0.3990846168765052,\n",
       " 0.4109082313771757,\n",
       " 0.41491576832113086,\n",
       " 0.4161080627521967,\n",
       " 0.4115819905289868,\n",
       " 0.41690303794331385,\n",
       " 0.41690303794331385,\n",
       " 0.4101950770125904,\n",
       " 0.426516143282746,\n",
       " 0.43202137173457444,\n",
       " 0.4308900220343821,\n",
       " 0.44655584826984285,\n",
       " 0.437150157042113,\n",
       " 0.4756254747628206,\n",
       " 0.4869871214692463,\n",
       " 0.49575642849061774,\n",
       " 0.48889526395465976,\n",
       " 0.48657262995706274,\n",
       " 0.4859513977556178,\n",
       " 0.47686120494130435,\n",
       " 0.49537325112192176,\n",
       " 0.4922973941245239,\n",
       " 0.49667329314348185,\n",
       " 0.498199941816301,\n",
       " 0.5109905909416601,\n",
       " 0.5288221437460603,\n",
       " 0.5156631325456984,\n",
       " 0.5215320091154463,\n",
       " 0.5073372742014555,\n",
       " 0.5086800785479935,\n",
       " 0.5067918020245772,\n",
       " 0.5125468702018652,\n",
       " 0.5177298660158711,\n",
       " 0.5260638054294011,\n",
       " 0.5393238299958516,\n",
       " 0.5055345223279946,\n",
       " 0.5254274212230428,\n",
       " 0.5256819749055861,\n",
       " 0.5394305674526851,\n",
       " 0.5509642735926819,\n",
       " 0.5312875433010631,\n",
       " 0.5072113442050652,\n",
       " 0.5179652571678162,\n",
       " 0.5129829049110413,\n",
       " 0.5107245445251465,\n",
       " 0.5092712640762329,\n",
       " 0.5082036852836609,\n",
       " 0.5073413848876953,\n",
       " 0.5065695643424988,\n",
       " 0.5058115720748901,\n",
       " 0.505020022392273,\n",
       " 0.5041698217391968]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 60 into shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-645670901f82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mforex_input\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforex_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforex_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mforex_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\forex\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    297\u001b[0m            [5, 6]])\n\u001b[0;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\forex\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 60 into shape (1,)"
     ]
    }
   ],
   "source": [
    "forex_input= np.reshape(forex_input,(forex_input.shape[0]))\n",
    "forex_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "days=np.arange(1,11)\n",
    "\n",
    "plt.plot(days,predictions)\n",
    "print(predictions[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
